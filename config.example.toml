# OpenRouter API key
# Get one at https://openrouter.ai/settings/keys
api_key = "your-openrouter-api-key-here"

# Model to use
# Common options:
# - anthropic/claude-sonnet-4
# - anthropic/claude-3.5-haiku
# - openai/gpt-4o
# - openai/gpt-4o-mini
# - meta-llama/llama-3.1-70b-instruct
#
# See models.example.toml for free model options with context window sizes
model = "xiaomi/mimo-v2-flash:free"

# Context window limit (tokens)
# Used for calculating when to warn about approaching limits
# If using models.toml, the context_window from there takes precedence
context_window_limit = 100000

# Warning threshold percentage (0.0-100.0)
# When context usage exceeds this percentage, a warning is printed to stderr
warn_threshold_percent = 80.0

# Auto-compaction settings
# When enabled, chibi will automatically compact the context when it reaches
# the threshold percentage of the context window
auto_compact = false
auto_compact_threshold = 80.0

# Optional: Custom API base URL
# Default: https://openrouter.ai/api/v1/chat/completions
# base_url = "https://openrouter.ai/api/v1/chat/completions"

# Reflection settings
# When enabled, the LLM has access to a persistent memory that spans all contexts.
# The LLM can use the update_reflection tool to store notes, preferences, and insights.
reflection_enabled = true
reflection_character_limit = 10000

# Maximum recursion depth for tool execution loops
# Prevents runaway agent loops
max_recursion_depth = 15

# Default username shown to the LLM
# Can be overridden per-context in local.toml or via -u/-U flags
username = "user"

# Context lock heartbeat interval (seconds)
# Used to detect stale locks from crashed sessions
lock_heartbeat_seconds = 30
